{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743c5c3e-ab3a-4a86-9c53-f9bfa8da9d6f",
   "metadata": {},
   "source": [
    "## Inconsistent Date Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b82c5f-2e90-447a-b20c-3a1189ac06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def INCONSISTENT_DATE_CHECK(sources,df,measure):\n",
    "    try:\n",
    "        # df = pd.read_csv('Downloads/config3.csv')\n",
    "        \n",
    "        inconsistency_date_check_rows = df[(df['Function_Type']=='Inconsistent_Date_Check') & (df['DataSource'] == sources)]\n",
    "        engine = create_engine(db_connection_string)\n",
    "\n",
    "        result_list = []\n",
    "        for index, row in inconsistency_date_check_rows.iterrows():\n",
    "            test_case_id = row['TC_ID']\n",
    "            \n",
    "            data_source = row['DataSource']\n",
    "            table_name = row['TableName']\n",
    "            column_name = row['Column']\n",
    "            base_table_member = row['BaseTableMember']\n",
    "            check_data_source = row['checkdatasource']\n",
    "            check_table = row['check_table']\n",
    "            check_column = row['check_column']\n",
    "            check_table_member = row['CheckTableMember']\n",
    "\n",
    "            query = f\"\"\"\n",
    "            WITH base_data AS (\n",
    "                SELECT DISTINCT [{base_table_member}], [{column_name}] \n",
    "                FROM [{data_source}].[{table_name}]\n",
    "            ),\n",
    "            check_data AS (\n",
    "                SELECT DISTINCT [{check_table_member}], [{check_column}]\n",
    "                FROM [{check_data_source}].[{check_table}]\n",
    "            ),\n",
    "           \n",
    "            inconsistent_members AS (\n",
    "                SELECT b.[{base_table_member}]\n",
    "                FROM base_data b\n",
    "                INNER JOIN check_data c ON cast(b.[{base_table_member}] as nvarchar) = cast(c.[{check_table_member}] as nvarchar)\n",
    "                WHERE cast(b.[{column_name}] as date) != cast(c.[{check_column}] as date)\n",
    "            )\n",
    "            SELECT \n",
    "                (SELECT COUNT(DISTINCT [{base_table_member}]) FROM base_data),\n",
    "                (SELECT COUNT(DISTINCT [{base_table_member}]) FROM inconsistent_members)\n",
    "            \"\"\"\n",
    "            \n",
    "            query2 = f\"\"\"\n",
    "            WITH base_data AS (\n",
    "                SELECT DISTINCT [{base_table_member}], [{column_name}] \n",
    "                FROM [{data_source}].[{table_name}]\n",
    "            ),\n",
    "            check_data AS (\n",
    "                SELECT DISTINCT [{check_table_member}], [{check_column}]\n",
    "                FROM [{check_data_source}].[{check_table}]\n",
    "            ),\n",
    "           \n",
    "            inconsistent_members AS (\n",
    "                SELECT b.[{base_table_member}],b.[{column_name}] as primary_date, c.[{check_column}] as comparing_Date\n",
    "                FROM base_data b\n",
    "                INNER JOIN check_data c ON cast(b.[{base_table_member}] as nvarchar) = cast(c.[{check_table_member}] as nvarchar)\n",
    "                WHERE cast(b.[{column_name}] as date) != cast(c.[{check_column}] as date)\n",
    "            )\n",
    "            SELECT * from inconsistent_members\n",
    "                \n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(text(query)).fetchone()\n",
    "                result2 = conn.execute(text(query2)).fetchall()\n",
    "            # print(result)\n",
    "            # print(result2)\n",
    "            total_members, inconsistent_members = result\n",
    "            invalid_member_data = []\n",
    "            invalid_rows = 0\n",
    "            for row in result2:\n",
    "                invalid_rows += 1\n",
    "                invalid_member_data.append({\n",
    "                        'MemberId': row[0],\n",
    "                        'Primary Date': row[1].strftime('%m/%d/%Y') if row[1] else None,\n",
    "                        'Comparing Date': row[2].strftime('%m/%d/%Y') if row[2] else None,\n",
    "                        'Error Flag' : 1\n",
    "            })\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            member_percentage = (inconsistent_members / total_members) * 100 if total_members > 0 else 0\n",
    "            error_flag = 1 if inconsistent_members > 0 else 0 \n",
    "\n",
    "            result_list.append({\n",
    "                'DVE Run Date' : date.today().strftime('%m%d%Y'),\n",
    "                'TestCaseID': test_case_id,\n",
    "                'Measure':measure,\n",
    "                'Function' : \"Inconsistent Date Check\",\n",
    "                \"Comparision\" : \"% of values with inconsistent date\",\n",
    "                'DataSource': data_source,\n",
    "                'TableName': table_name,\n",
    "                'ColumnName': column_name,\n",
    "                'Check Data Source' : check_data_source,\n",
    "                'Check Table Name' : check_table,\n",
    "                'Check Column Name' :check_column,\n",
    "                'Total Unique Member IDs': total_members,\n",
    "                'Inconsistent Date Member IDs': inconsistent_members,\n",
    "                'Member Percentage': f\"{member_percentage:.2f}%\",\n",
    "                'Invalid Member Data' : invalid_member_data,\n",
    "                'Error Flag': error_flag\n",
    "            })\n",
    "\n",
    "        result_json = json.dumps(result_list)\n",
    "        return result_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\"error\": \"Excel file not found.\"})\n",
    "    except SQLAlchemyError as e:\n",
    "        return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An error occurred: {str(e)}\"})\n",
    "db_connection_string = 'mssql+pyodbc://zsaudit:9v]3>SYv1C20@lhp-db-copy.database.windows.net:1433/HEDIS_2023_Copy?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "# b = INCONSISTENT_DATE_CHECK('LWCC')\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3337f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c64be6-19d1-4a90-b561-890ae9361935",
   "metadata": {},
   "source": [
    "## Date Format Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f05f8c-b8b5-4ecd-bf4a-687150a9dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def DATE_FORMAT_CHECK(sources,df,measure):\n",
    "    try:\n",
    "        # df = pd.read_csv('Downloads/config3.csv')\n",
    "        date_format_check_rows = df[(df['Function_Type'] == 'Date_Format_Check') & (df['DataSource'] == sources)]\n",
    "        engine = create_engine(db_connection_string)\n",
    "        print(\"engine created\")\n",
    "        result_list = []\n",
    "        today = date.today()\n",
    "        for index, row in date_format_check_rows.iterrows():\n",
    "            test_case_id = row['TC_ID']\n",
    "            data_source = row['DataSource']\n",
    "            table_name = row['TableName']\n",
    "            base_table_member = row['BaseTableMember']\n",
    "            column_name = row['Column']\n",
    "            print(column_name)\n",
    "            # Modified query to get member ids and dates with incorrect format or 1/1/1900\n",
    "            query = f\"\"\"\n",
    "                SELECT\n",
    "                    {column_name},\n",
    "                    [{base_table_member}]\n",
    "                    \n",
    "                FROM {data_source}.{table_name}\n",
    "                WHERE\n",
    "                    {column_name} is NULL\n",
    "                    OR TRY_CONVERT(DATE, {column_name}) IS NULL\n",
    "                    OR {column_name} = '1900-01-01'  \n",
    "            \"\"\"\n",
    "\n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(text(query)).fetchall()  # Fetch all rows\n",
    "\n",
    "                total_rows = 0\n",
    "                invalid_rows = 0\n",
    "                invalid_member_data = []  # Store member ids and dates\n",
    "\n",
    "                for row in result:\n",
    "                    total_rows += 1\n",
    "                    invalid_rows += 1\n",
    "                    invalid_member_data.append({\n",
    "                        'MemberId': row[1],\n",
    "                        'Date': row[0].strftime('%m/%d/%Y') if row[0] else None,\n",
    "                        'Error' : 1\n",
    "                    })\n",
    "\n",
    "                if total_rows > 0:\n",
    "                    invalid_percentage = (invalid_rows / total_rows) * 100\n",
    "                else:\n",
    "                    invalid_percentage = 0\n",
    "\n",
    "                error_flag = 1 if invalid_rows > 0 else 0\n",
    "                result_list.append({\n",
    "                    'DVE_Run_Date' : str(today),\n",
    "                    'TestCaseID': test_case_id,\n",
    "                    'Measure' : measure,\n",
    "                    'Function' : \"Date Format Check\",\n",
    "                    'Comparision' : '% of dates with incorrect format',\n",
    "                    'DataSource': data_source,\n",
    "                    'TableName': table_name,\n",
    "                    'ColumnName': column_name,\n",
    "                    'Total rows': total_rows,\n",
    "                    'Invalid Rows': invalid_rows,\n",
    "                    'Percentage': f\"{invalid_percentage:.2f}%\",\n",
    "                    'Error Flag': error_flag,\n",
    "                    'InvalidMemberData': invalid_member_data\n",
    "                })\n",
    "\n",
    "        result_json = json.dumps(result_list)\n",
    "        return result_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\"error\": \"Excel file not found.\"})\n",
    "    except SQLAlchemyError as e:\n",
    "        return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An error occurred: {str(e)}\"})\n",
    "\n",
    "\n",
    "\n",
    "# db_connection_string = 'mssql+pyodbc://zsaudit:9v]3>SYv1C20@lhp-db-copy.database.windows.net:1433/HEDIS_2023_Copy?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "# print(DATE_FORMAT_CHECK('LWCC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe7e2b-54af-4fe0-8196-12271f40a887",
   "metadata": {},
   "source": [
    "## Age Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd470c3-9b2c-4c99-8c95-4b52fc75f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGE_CHECK_pre(sources,table_name,columnname, threshold = 0.1,previous_results = {}):\n",
    "    try:\n",
    "        engine = create_engine(db_connection_string)\n",
    "        today = date.today()\n",
    "            # print(current_counts)\n",
    "        # today = datetime.now().strftime('%m%d%Y')\n",
    "        query = f\"\"\"\n",
    "                SELECT age_group,count(distinct memberID) as members from\n",
    "                (select memberID,\n",
    "                    CASE\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 0 AND 5 THEN '0-5'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 6 AND 10 THEN '6-10'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 11 AND 15 THEN '11-15'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 16 AND 20 THEN '16-20'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 21 AND 25 THEN '21-25'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 26 AND 30 THEN '26-30'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 31 AND 35 THEN '31-35'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 36 AND 40 THEN '36-40'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 41 AND 45 THEN '41-45'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 46 AND 50 THEN '46-50'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 51 AND 55 THEN '51-55'\n",
    "                        WHEN DATEDIFF(YEAR, {columnname}, cast(GETDATE() as date)) BETWEEN 56 AND 60 THEN '56-60'\n",
    "                        \n",
    "                        ELSE 'Other'\n",
    "                    END AS age_group\n",
    "                    FROM {sources}.{table_name}\n",
    "                     )as subquery\n",
    "                    \n",
    "                GROUP BY age_group\n",
    "                \"\"\"\n",
    "        with engine.connect() as conn:\n",
    "            current_year_results = conn.execute(text(query)).fetchall()\n",
    "        current_year_total = sum(row[1] for row in current_year_results)\n",
    "        \n",
    "        current_year_counts = {row[0]: row[1] for row in current_year_results}\n",
    "        # for row in current_year_results:\n",
    "        #     print(row)\n",
    "        today = date.today().strftime('%m%d%Y')\n",
    "        \n",
    "        if today in previous_results:\n",
    "            previous_counts = previous_results[today]\n",
    "        else:\n",
    "            if previous_results:\n",
    "                latest_date = max(previous_results.keys())\n",
    "                       \n",
    "                previous_counts = previous_results[latest_date]\n",
    "            else:\n",
    "                previous_counts = current_year_counts.copy()\n",
    "                \n",
    "       \n",
    "                \n",
    "        error_flag = 0\n",
    "        error_flag_list = []\n",
    "        for category,current_count in current_year_counts.items():\n",
    "            \n",
    "            previous_count = previous_counts.get(category,0)\n",
    "            # print(category,current_count,previous_count)\n",
    "            if previous_count>0:\n",
    "                percentage_change = abs((current_count - previous_count)/previous_count)\n",
    "            else:\n",
    "                percentage_change = current_count\n",
    "            if percentage_change>threshold:\n",
    "                error_flag = 1\n",
    "                error_flag_list.append(1)\n",
    "            else:\n",
    "                error_flag_list.append(0)\n",
    "        print(error_flag_list)\n",
    "            \n",
    "                      \n",
    "        previous_results[today] = current_year_counts\n",
    "\n",
    "                # print(current_year_counts)\n",
    "                # print(\"--------\")\n",
    "                # print(previous_results)\n",
    "        return current_year_counts,previous_results,error_flag,error_flag_list\n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\"error\": \"Excel file not found.\"})\n",
    "    except SQLAlchemyError as e:\n",
    "        return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An error occurred: {e}\"})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11a88d-de57-4056-957e-87c7aaa495cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGE_CHECK_main(sources,final_list,df,measure):\n",
    "    # measure_to_value_filtered = measure_to_value[measure_to_value['Measure ID']==measure]\n",
    "    # df = pd.read_csv('config3.csv')\n",
    "    age_check_rows = df[(df['Function_Type'] == 'Age_Check') & (df['DataSource'] == sources)]\n",
    "    engine = create_engine(db_connection_string)\n",
    "    value_set_final_list = []\n",
    "    source_rows = age_check_rows[age_check_rows['DataSource'] == sources]\n",
    "    for index, row in source_rows.iterrows():\n",
    "        value_set_final_dict = {}\n",
    "        test_case_id = row['TC_ID']\n",
    "        table_name = row['TableName']\n",
    "        columnname = row['Column']  \n",
    "        \n",
    "        # filtered_data = [d for d in final_list]\n",
    "        result = None\n",
    "        # for d in filtered_data:\n",
    "        #     if code_system in d['Previous Count']:\n",
    "        if len(final_list) !=0:\n",
    "            result = final_list[0]\n",
    "                \n",
    "        if result is not None:  \n",
    "            previous_results = {}\n",
    "            date_prev = result['DVE Run Date']\n",
    "            previous_results[date_prev] = result['Previous Count']\n",
    "        else:\n",
    "            previous_results = {}\n",
    "        current_counts,previous_results,error_flag,error_flag_list = AGE_CHECK_pre(sources,table_name,columnname, threshold = 0.1,previous_results = {})\n",
    "        value_set_final_dict['DVE Run Date'] = date.today().strftime('%m%d%Y')\n",
    "        value_set_final_dict['Test Case ID'] = test_case_id\n",
    "        value_set_final_dict['Measure'] = measure\n",
    "        value_set_final_dict['Function'] = \"Age Check\"\n",
    "        value_set_final_dict['Comparision'] = \"% of members with inconsistent Age\"\n",
    "        value_set_final_dict['Datasource'] = sources\n",
    "        value_set_final_dict['TableName'] = table_name\n",
    "        value_set_final_dict['ColumnName'] = columnname\n",
    "        value_set_final_dict['Current Count'] = current_counts\n",
    "        value_set_final_dict['Previous Count'] = previous_results\n",
    "        value_set_final_dict['Error Flag Individual'] = error_flag_list\n",
    "        value_set_final_dict['Error Flag'] = error_flag\n",
    "        value_set_final_list.append(value_set_final_dict)\n",
    "    return value_set_final_list\n",
    "        \n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b7dec1-7dae-4dee-816d-771cabb27954",
   "metadata": {},
   "source": [
    "## Future Date Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e9e3f-25e4-4879-ab4a-cf24f2d12a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUTURE_DATE_CHECK(sources,df,measure):\n",
    "    try:\n",
    "        # df = pd.read_csv('config3.csv')\n",
    "        future_date_check_rows = df[(df['Function_Type'] == 'Future_Date_Check') & (df['DataSource'] == sources)]\n",
    "        engine = create_engine(db_connection_string)\n",
    "        threshold_percentage = 0\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for index, row in future_date_check_rows.iterrows():\n",
    "            test_case_id = row['TC_ID']\n",
    "            data_source = row['DataSource']\n",
    "            table_name = row['TableName']\n",
    "            column_name = row['Column']\n",
    "            base_table_member = row['BaseTableMember']\n",
    "            check_data_source = row['checkdatasource']\n",
    "            check_table = row['check_table']\n",
    "            check_column = row['check_column']\n",
    "            check_table_member = row['CheckTableMember']\n",
    "\n",
    "            query = f\"\"\"\n",
    "            WITH base_data AS (\n",
    "                SELECT   [{base_table_member}], max({column_name}) as column_name\n",
    "                FROM [{data_source}].[{table_name}] group by [{base_table_member}]\n",
    "            ),\n",
    "            check_data AS (\n",
    "                SELECT  [{check_table_member}], max({check_column}) as check_column\n",
    "                FROM [{check_data_source}].[{check_table}] group by [{check_table_member}]\n",
    "            ),\n",
    "            inconsistent_members AS (\n",
    "                SELECT distinct(b.[{base_table_member}]),b.column_name, c.check_column\n",
    "                FROM base_data b\n",
    "                JOIN check_data c ON cast(b.[{base_table_member}] as nvarchar) = cast(c.[{check_table_member}] as nvarchar)\n",
    "                WHERE cast(b.column_name as date) < cast(c.check_column as date) \n",
    "                \n",
    "            )\n",
    "            SELECT * from inconsistent_members\n",
    "                \n",
    "            \"\"\"\n",
    "            query2 = f\"\"\"\n",
    "            WITH base_data AS (\n",
    "                SELECT DISTINCT  [{base_table_member}], {column_name}\n",
    "                FROM [{data_source}].[{table_name}]\n",
    "            ),\n",
    "            check_data AS (\n",
    "                SELECT DISTINCT [{check_table_member}], {check_column}\n",
    "                FROM [{check_data_source}].[{check_table}]\n",
    "            ),\n",
    "            inconsistent_members AS (\n",
    "                SELECT b.[{base_table_member}], b.{column_name}, c.{check_column}\n",
    "                FROM base_data b\n",
    "                JOIN check_data c ON cast(b.[{base_table_member}] as nvarchar) = cast(c.[{check_table_member}] as nvarchar)\n",
    "                WHERE cast(b.{column_name} as date) < cast(c.{check_column} as date)\n",
    "            )\n",
    "            SELECT count(distinct [{base_table_member}]) from [{data_source}].[{table_name}]\n",
    "                \n",
    "            \"\"\"\n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(text(query)).fetchall()\n",
    "                result2 = conn.execute(text(query2)).fetchone()# Fetch all rows\n",
    "                \n",
    "                total_rows = result2[0]\n",
    "                invalid_rows = 0\n",
    "                invalid_member_data = []  # Store member ids and dates\n",
    "\n",
    "                for row in result:\n",
    "                    # print(row[1])\n",
    "                    # total_rows += 1\n",
    "                    invalid_rows += 1\n",
    "                    invalid_member_data.append({\n",
    "                        'MemberId': row[0],\n",
    "                        'Primary Date': row[1].strftime('%m/%d/%Y') if row[1] else None,\n",
    "                        'Comparing Date': row[2].strftime('%m/%d/%Y') if row[2] else None,\n",
    "                        'Error Flag' : 1\n",
    "                    })\n",
    "\n",
    "                if total_rows > 0:\n",
    "                    invalid_percentage = (invalid_rows / total_rows) * 100\n",
    "                else:\n",
    "                    invalid_percentage = 0\n",
    "\n",
    "                error_flag = 1 if invalid_rows > 0 else 0\n",
    "                result_list.append({\n",
    "                    'TestCaseID': test_case_id,\n",
    "                    'Measure': measure,\n",
    "                    'DataSource': data_source,\n",
    "                    'Comparision': '% of dates in future',\n",
    "                    'TableName': table_name,\n",
    "                    'ColumnName': column_name,\n",
    "                    'CheckTableName': check_table,\n",
    "                    'CheckColumnName': check_column,\n",
    "                    'Total Unique Member IDs': total_rows,\n",
    "                    'Future Date Member IDs': invalid_rows,\n",
    "                    'Member Percentage': f\"{invalid_percentage:.2f}%\",\n",
    "                    'Error Flag': error_flag,\n",
    "                    'Invalid Member Data': invalid_member_data\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        result_json = json.dumps(result_list)\n",
    "        return result_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\"error\": \"Excel file not found.\"})\n",
    "    except SQLAlchemyError as e:\n",
    "        return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An error occurred: {str(e)}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cfb6e-e3da-4d93-bdee-c06aaea3eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
